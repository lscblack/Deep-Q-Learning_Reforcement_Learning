[
  {
    "experiment": 1,
    "mean_reward": -10.666666666666666,
    "std_reward": 2.6246692913372702,
    "model_path": "TamandaKaunda_results/exp_1/final_model.zip",
    "hyperparameters": {
      "lr": 0.0004,
      "gamma": 0.995,
      "batch_size": 64,
      "eps_start": 1.0,
      "eps_end": 0.02,
      "eps_decay": 300000.0,
      "policy": "CnnPolicy",
      "buffer_size": 20000,
      "description": "1. Moderate Aggressive LR, Long Exploration"
    }
  },
  {
    "experiment": 2,
    "mean_reward": -18.0,
    "std_reward": 4.242640687119285,
    "model_path": "TamandaKaunda_results/exp_2/final_model.zip",
    "hyperparameters": {
      "lr": 0.0002,
      "gamma": 0.8,
      "batch_size": 32,
      "eps_start": 1.0,
      "eps_end": 0.01,
      "eps_decay": 100000.0,
      "policy": "CnnPolicy",
      "buffer_size": 20000,
      "description": "2. Extreme Short Horizon (Gamma 0.80)"
    }
  },
  {
    "experiment": 3,
    "mean_reward": -22.333333333333332,
    "std_reward": 3.0912061651652345,
    "model_path": "TamandaKaunda_results/exp_3/final_model.zip",
    "hyperparameters": {
      "lr": 0.0001,
      "gamma": 0.99,
      "batch_size": 128,
      "eps_start": 0.7,
      "eps_end": 0.05,
      "eps_decay": 50000.0,
      "policy": "CnnPolicy",
      "buffer_size": 50000,
      "description": "3. Low Initial Epsilon (0.7), Fast Decay"
    }
  },
  {
    "experiment": 4,
    "mean_reward": -19.0,
    "std_reward": 0.0,
    "model_path": "TamandaKaunda_results/exp_4/final_model.zip",
    "hyperparameters": {
      "lr": 6e-05,
      "gamma": 0.96,
      "batch_size": 64,
      "eps_start": 1.0,
      "eps_end": 0.25,
      "eps_decay": 200000.0,
      "policy": "CnnPolicy",
      "buffer_size": 50000,
      "description": "4. Sustained High Randomness (Eps End 0.25)"
    }
  },
  {
    "experiment": 5,
    "mean_reward": -20.0,
    "std_reward": 1.632993161855452,
    "model_path": "TamandaKaunda_results/exp_5/final_model.zip",
    "hyperparameters": {
      "lr": 0.0001,
      "gamma": 0.999,
      "batch_size": 32,
      "eps_start": 1.0,
      "eps_end": 0.01,
      "eps_decay": 250000.0,
      "policy": "MlpPolicy",
      "buffer_size": 20000,
      "description": "5. MlpPolicy Test 3 (Expected Failure)"
    }
  },
  {
    "experiment": 6,
    "mean_reward": -1.0,
    "std_reward": 1.4142135623730951,
    "model_path": "TamandaKaunda_results/exp_6/final_model.zip",
    "hyperparameters": {
      "lr": 0.0003,
      "gamma": 0.97,
      "batch_size": 64,
      "eps_start": 0.95,
      "eps_end": 0.005,
      "eps_decay": 400000.0,
      "policy": "CnnPolicy",
      "buffer_size": 20000,
      "description": "6. Precision Exploiter (Low Eps End 0.005)"
    }
  },
  {
    "experiment": 7,
    "mean_reward": -12.333333333333334,
    "std_reward": 2.0548046676563256,
    "model_path": "TamandaKaunda_results/exp_7/final_model.zip",
    "hyperparameters": {
      "lr": 5e-05,
      "gamma": 0.99999,
      "batch_size": 128,
      "eps_start": 1.0,
      "eps_end": 0.05,
      "eps_decay": 500000.0,
      "policy": "CnnPolicy",
      "buffer_size": 20000,
      "description": "7. Near Undiscounted Future (Max Gamma)"
    }
  },
  {
    "experiment": 8,
    "mean_reward": -16.666666666666668,
    "std_reward": 5.2493385826745405,
    "model_path": "TamandaKaunda_results/exp_8/final_model.zip",
    "hyperparameters": {
      "lr": 0.0002,
      "gamma": 0.99,
      "batch_size": 256,
      "eps_start": 1.0,
      "eps_end": 0.02,
      "eps_decay": 1000000.0,
      "policy": "CnnPolicy",
      "buffer_size": 20000,
      "description": "8. Large Batch, Smooth Ultra-Slow Decay"
    }
  },
  {
    "experiment": 9,
    "mean_reward": -17.666666666666668,
    "std_reward": 0.9428090415820634,
    "model_path": "TamandaKaunda_results/exp_9/final_model.zip",
    "hyperparameters": {
      "lr": 8e-05,
      "gamma": 0.98,
      "batch_size": 32,
      "eps_start": 1.0,
      "eps_end": 0.01,
      "eps_decay": 200000.0,
      "policy": "MlpPolicy",
      "buffer_size": 20000,
      "description": "9. MlpPolicy Test 4 (Expected Failure)"
    }
  },
  {
    "experiment": 10,
    "mean_reward": -5.666666666666667,
    "std_reward": 3.39934634239519,
    "model_path": "TamandaKaunda_results/exp_10/final_model.zip",
    "hyperparameters": {
      "lr": 0.0004,
      "gamma": 0.995,
      "batch_size": 64,
      "eps_start": 1.0,
      "eps_end": 0.02,
      "eps_decay": 300000.0,
      "policy": "CnnPolicy",
      "buffer_size": 10000,
      "description": "11. Final Optimized Run: Best LR/Gamma with Smaller Buffer"
    }
  }
]